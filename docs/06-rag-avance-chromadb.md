# √âtape 6 : RAG Avanc√© avec ChromaDB

## üéØ Objectif

Am√©liorer le RAG avec ChromaDB pour avoir une base vectorielle persistante et performante.

## ‚è±Ô∏è Dur√©e Estim√©e

15-20 minutes

## üìã Pr√©requis

- ‚úÖ √âtape 5 (RAG simple) compl√©t√©e
- ‚úÖ Environnement `rag` activ√©
- ‚úÖ Documents de test fonctionnels

---

## üöÄ Pourquoi ChromaDB ?

### Probl√®mes du RAG Simple
- ‚ùå Recalcule les embeddings √† chaque requ√™te
- ‚ùå Lent avec beaucoup de documents
- ‚ùå Pas de persistance (tout en m√©moire)

### Avantages de ChromaDB
- ‚úÖ **Persistance** : Embeddings sauvegard√©s sur disque
- ‚úÖ **Rapidit√©** : Index optimis√© pour recherche vectorielle
- ‚úÖ **Scalabilit√©** : G√®re facilement 1000+ documents
- ‚úÖ **M√©tadonn√©es** : Stocke source, page, date, etc.
- ‚úÖ **Mise √† jour** : Ajout/suppression de documents facile

---

## üì¶ √âtape 1 : Installation de ChromaDB

```bash
# Activer l'environnement
conda activate rag

# Installer ChromaDB
pip install chromadb

# V√©rifier l'installation
python -c "import chromadb; print(f'ChromaDB version: {chromadb.__version__}')"
```

---

## üóÇÔ∏è √âtape 2 : Script d'Indexation avec ChromaDB

```bash
cat > ~/hp-z800-ai-agent/rag/scripts/index_documents.py << 'EOF'
#!/usr/bin/env python3
"""
Indexe tous les documents dans ChromaDB
"""

import chromadb
from pathlib import Path
from extract_text import extract_text, chunk_text
from generate_embeddings import generate_embedding
import hashlib

# Initialiser ChromaDB
client = chromadb.PersistentClient(path="../vectordb")

def get_or_create_collection():
    """Cr√©e ou r√©cup√®re la collection de documents"""
    try:
        # Essayer de r√©cup√©rer la collection existante
        collection = client.get_collection(name="documents")
        print(f"üìö Collection existante trouv√©e: {collection.count()} documents")
    except:
        # Cr√©er une nouvelle collection
        collection = client.create_collection(
            name="documents",
            metadata={"description": "Documents RAG"}
        )
        print("üìö Nouvelle collection cr√©√©e")
    
    return collection

def document_id(source: str, chunk_id: int) -> str:
    """G√©n√®re un ID unique pour un chunk"""
    content = f"{source}_{chunk_id}"
    return hashlib.md5(content.encode()).hexdigest()

def index_document(file_path: Path, collection):
    """Indexe un document dans ChromaDB"""
    print(f"\nüìÑ Indexation: {file_path.name}")
    
    # Extraire le texte
    text = extract_text(str(file_path))
    
    if "Erreur" in text or "non support√©" in text:
        print(f"  ‚ö†Ô∏è  Ignor√©: {text}")
        return 0
    
    # D√©couper en chunks
    chunks = chunk_text(text, chunk_size=500, overlap=50)
    print(f"  üìë {len(chunks)} chunks")
    
    # Indexer chaque chunk
    indexed = 0
    for i, chunk in enumerate(chunks):
        # G√©n√©rer embedding
        embedding = generate_embedding(chunk)
        
        # Ajouter √† ChromaDB
        collection.add(
            ids=[document_id(file_path.name, i)],
            embeddings=[embedding],
            documents=[chunk],
            metadatas=[{
                "source": file_path.name,
                "chunk_id": i,
                "total_chunks": len(chunks),
                "file_type": file_path.suffix
            }]
        )
        
        indexed += 1
        print(f"  ‚úì Chunk {i+1}/{len(chunks)}", end='\r')
    
    print(f"  ‚úÖ {indexed} chunks index√©s")
    return indexed

def index_all_documents(docs_folder: str):
    """Indexe tous les documents du dossier"""
    print("="*60)
    print("INDEXATION DES DOCUMENTS")
    print("="*60)
    
    collection = get_or_create_collection()
    docs_path = Path(docs_folder)
    
    total_indexed = 0
    total_files = 0
    
    # Parcourir tous les fichiers
    for file_path in docs_path.glob('*'):
        if file_path.suffix.lower() in ['.txt', '.pdf', '.docx']:
            total_files += 1
            indexed = index_document(file_path, collection)
            total_indexed += indexed
    
    print("\n" + "="*60)
    print(f"‚úÖ INDEXATION TERMIN√âE")
    print(f"   Fichiers trait√©s: {total_files}")
    print(f"   Chunks index√©s: {total_indexed}")
    print(f"   Total en base: {collection.count()}")
    print("="*60)

if __name__ == "__main__":
    import sys
    
    docs_folder = "../documents"
    if len(sys.argv) > 1:
        docs_folder = sys.argv[1]
    
    index_all_documents(docs_folder)
EOF

chmod +x ~/hp-z800-ai-agent/rag/scripts/index_documents.py
```

---

## üîç √âtape 3 : Script de Recherche avec ChromaDB

```bash
cat > ~/hp-z800-ai-agent/rag/scripts/rag_chromadb.py << 'EOF'
#!/usr/bin/env python3
"""
RAG avec ChromaDB - Version optimis√©e
"""

import chromadb
import requests
from generate_embeddings import generate_embedding

OLLAMA_URL = "http://localhost:11434"

# Initialiser ChromaDB
client = chromadb.PersistentClient(path="../vectordb")

def search_documents(query: str, top_k: int = 3):
    """Recherche dans ChromaDB"""
    print(f"\nüîç Recherche pour: '{query}'")
    
    # R√©cup√©rer la collection
    try:
        collection = client.get_collection(name="documents")
    except:
        print("‚ùå Aucune collection trouv√©e. Lancez d'abord: python index_documents.py")
        return []
    
    # G√©n√©rer embedding de la question
    query_embedding = generate_embedding(query)
    
    # Rechercher dans ChromaDB
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=top_k,
        include=["documents", "metadatas", "distances"]
    )
    
    # Afficher les r√©sultats
    print(f"\n‚úÖ Top {top_k} r√©sultats:")
    for i, (doc, metadata, distance) in enumerate(zip(
        results['documents'][0],
        results['metadatas'][0],
        results['distances'][0]
    ), 1):
        similarity = 1 - distance  # Convertir distance en similarit√©
        print(f"{i}. {metadata['source']} (chunk {metadata['chunk_id']+1}/{metadata['total_chunks']}) - similarit√©: {similarity:.3f}")
        print(f"   Preview: {doc[:100]}...")
    
    return results

def generate_answer(query: str, search_results):
    """G√©n√®re une r√©ponse avec Mistral"""
    
    if not search_results or not search_results['documents'][0]:
        return "Aucun document pertinent trouv√©."
    
    # Construire le contexte
    context_parts = []
    for doc, metadata in zip(
        search_results['documents'][0],
        search_results['metadatas'][0]
    ):
        context_parts.append(f"[Source: {metadata['source']}, partie {metadata['chunk_id']+1}]\n{doc}")
    
    context = "\n\n".join(context_parts)
    
    # Prompt avec contexte
    prompt = f"""Tu es un assistant qui r√©pond aux questions en te basant sur des documents fournis.

DOCUMENTS:
{context}

QUESTION: {query}

INSTRUCTIONS:
- R√©ponds UNIQUEMENT en te basant sur les documents fournis ci-dessus
- Si l'information n'est pas dans les documents, dis-le clairement
- Cite les sources quand c'est pertinent
- Sois pr√©cis et concis

R√âPONSE:"""

    # Appel √† Mistral
    print("\nüí¨ G√©n√©ration de la r√©ponse...")
    response = requests.post(
        f"{OLLAMA_URL}/api/generate",
        json={
            "model": "mistral",
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.1,  # Plus d√©terministe
                "top_p": 0.9
            }
        }
    )
    
    if response.status_code == 200:
        return response.json()['response']
    else:
        return f"Erreur API: {response.status_code}"

def rag_query(query: str, top_k: int = 3):
    """Pipeline RAG complet avec ChromaDB"""
    print("="*60)
    print("RAG avec ChromaDB")
    print("="*60)
    
    # 1. Rechercher documents pertinents
    results = search_documents(query, top_k)
    
    if not results:
        print("\n‚ùå Aucun r√©sultat")
        return
    
    # 2. G√©n√©rer r√©ponse
    answer = generate_answer(query, results)
    
    print("\n" + "="*60)
    print("R√âPONSE:")
    print("="*60)
    print(answer)
    print("="*60)
    
    return answer

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python rag_chromadb.py <question>")
        print('Exemple: python rag_chromadb.py "Quelle est la conclusion ?"')
        sys.exit(1)
    
    query = " ".join(sys.argv[1:])
    rag_query(query, top_k=3)
EOF

chmod +x ~/hp-z800-ai-agent/rag/scripts/rag_chromadb.py
```

---

## üß™ √âtape 4 : Test de ChromaDB

### 4.1 Indexer les Documents

```bash
cd ~/hp-z800-ai-agent/rag/scripts

# Indexer tous les documents
python index_documents.py
```

**‚úÖ R√©sultat attendu :**
```
============================================================
INDEXATION DES DOCUMENTS
============================================================
üìö Nouvelle collection cr√©√©e

üìÑ Indexation: test-doc.txt
  üìë 2 chunks
  ‚úÖ 2 chunks index√©s

============================================================
‚úÖ INDEXATION TERMIN√âE
   Fichiers trait√©s: 1
   Chunks index√©s: 2
   Total en base: 2
============================================================
```

### 4.2 Tester la Recherche

```bash
# Premi√®re question
python rag_chromadb.py "Quelles sont les sp√©cifications du HP Z800 ?"

# Deuxi√®me question
python rag_chromadb.py "Comment nettoyer le Z800 ?"

# Troisi√®me question
python rag_chromadb.py "Quelle est la configuration r√©seau recommand√©e ?"
```

**‚úÖ Cette fois, c'est BEAUCOUP plus rapide !** (pas de recalcul des embeddings)

---

## üìä √âtape 5 : Script de Gestion de la Base

```bash
cat > ~/hp-z800-ai-agent/rag/scripts/manage_db.py << 'EOF'
#!/usr/bin/env python3
"""
Gestion de la base ChromaDB
"""

import chromadb
import sys

client = chromadb.PersistentClient(path="../vectordb")

def stats():
    """Affiche les statistiques de la base"""
    try:
        collection = client.get_collection(name="documents")
        count = collection.count()
        
        print("="*60)
        print("STATISTIQUES DE LA BASE VECTORIELLE")
        print("="*60)
        print(f"Total de chunks: {count}")
        
        # Lister les sources
        if count > 0:
            all_data = collection.get(include=["metadatas"])
            sources = set(m['source'] for m in all_data['metadatas'])
            
            print(f"\nDocuments index√©s: {len(sources)}")
            for source in sorted(sources):
                chunks = sum(1 for m in all_data['metadatas'] if m['source'] == source)
                print(f"  - {source}: {chunks} chunks")
        
        print("="*60)
    except:
        print("‚ùå Aucune collection trouv√©e")

def reset():
    """R√©initialise la base"""
    try:
        client.delete_collection(name="documents")
        print("‚úÖ Base r√©initialis√©e")
    except:
        print("‚ö†Ô∏è  Aucune collection √† supprimer")

def search_by_source(source: str):
    """Recherche tous les chunks d'une source"""
    try:
        collection = client.get_collection(name="documents")
        results = collection.get(
            where={"source": source},
            include=["documents", "metadatas"]
        )
        
        print(f"\nüìÑ Chunks de '{source}':")
        for i, (doc, meta) in enumerate(zip(results['documents'], results['metadatas']), 1):
            print(f"\n--- Chunk {i} ---")
            print(doc[:200] + ("..." if len(doc) > 200 else ""))
        
        print(f"\n‚úÖ Total: {len(results['documents'])} chunks")
    except Exception as e:
        print(f"‚ùå Erreur: {e}")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage:")
        print("  python manage_db.py stats              # Statistiques")
        print("  python manage_db.py reset              # R√©initialiser")
        print("  python manage_db.py search <filename>  # Voir chunks d'un fichier")
        sys.exit(1)
    
    cmd = sys.argv[1]
    
    if cmd == "stats":
        stats()
    elif cmd == "reset":
        confirm = input("‚ö†Ô∏è  √ätes-vous s√ªr de vouloir r√©initialiser la base ? (oui/non): ")
        if confirm.lower() == "oui":
            reset()
    elif cmd == "search" and len(sys.argv) > 2:
        search_by_source(sys.argv[2])
    else:
        print("‚ùå Commande inconnue")
EOF

chmod +x ~/hp-z800-ai-agent/rag/scripts/manage_db.py
```

**Utilisation :**
```bash
# Voir les stats
python manage_db.py stats

# Voir les chunks d'un document
python manage_db.py search test-doc.txt

# R√©initialiser la base
python manage_db.py reset
```

---

## üöÄ √âtape 6 : Workflow Complet

### 1Ô∏è‚É£ Ajouter de Nouveaux Documents

```bash
# Copier vos documents
cp ~/Documents/rapport.pdf ~/hp-z800-ai-agent/rag/documents/
cp ~/Documents/notes.docx ~/hp-z800-ai-agent/rag/documents/

# R√©indexer tout
cd ~/hp-z800-ai-agent/rag/scripts
python index_documents.py
```

### 2Ô∏è‚É£ Interroger la Base

```bash
python rag_chromadb.py "Votre question"
```

### 3Ô∏è‚É£ V√©rifier la Base

```bash
python manage_db.py stats
```

---

## üìà Comparaison : Simple vs ChromaDB

| Crit√®re | RAG Simple | RAG ChromaDB |
|---------|-----------|--------------|
| **Premi√®re requ√™te** | ~15 secondes | ~20 secondes (indexation) |
| **Requ√™tes suivantes** | ~15 secondes | **~3 secondes** ‚ö° |
| **10 documents** | ~2 minutes | ~5 secondes ‚ö° |
| **100 documents** | ~20 minutes | ~10 secondes ‚ö° |
| **Persistance** | ‚ùå Non | ‚úÖ Oui |
| **Scalabilit√©** | ‚ùå Limit√© | ‚úÖ Excellente |

---

## ‚úÖ Checklist de Validation

- [ ] ChromaDB install√©
- [ ] Documents index√©s avec succ√®s
- [ ] Base vectorielle cr√©√©e (`~/hp-z800-ai-agent/rag/vectordb/`)
- [ ] Requ√™tes plus rapides qu'avant
- [ ] Stats de la base fonctionnelles
- [ ] Ajout de nouveaux documents fonctionne

---

## üîß Scripts Utiles

### R√©indexer Automatiquement

```bash
cat > ~/hp-z800-ai-agent/rag/scripts/auto_index.sh << 'EOF'
#!/bin/bash
# Surveille le dossier documents et r√©indexe automatiquement

DOCS_DIR="../documents"

while true; do
    echo "üîÑ V√©rification de nouveaux documents..."
    python index_documents.py
    echo "‚úÖ Prochaine v√©rification dans 5 minutes"
    sleep 300
done
EOF

chmod +x ~/hp-z800-ai-agent/rag/scripts/auto_index.sh
```

---

## üìä R√©sum√© ChromaDB

```
‚úÖ Base vectorielle persistante (ChromaDB)
‚úÖ Indexation automatique des documents
‚úÖ Recherche ultra-rapide (5-10x plus rapide)
‚úÖ M√©tadonn√©es enrichies (source, chunk, type)
‚úÖ Gestion facile (stats, reset, search)
‚úÖ Scalable (1000+ documents)

Performance:
- Simple RAG: 15s par requ√™te
- ChromaDB: 3s par requ√™te ‚ö°
- √âconomie: ~80% de temps
```

---

## ‚û°Ô∏è Prochaine √âtape

**[√âtape 7 : Fine-tuning Setup](07-finetuning-setup.md)** *(optionnel)*

Pr√©parer l'environnement pour fine-tuner Mistral sur vos propres donn√©es.

---

## üÜò D√©pannage

### Probl√®me : "No module named 'chromadb'"

```bash
conda activate rag
pip install chromadb
```

### Probl√®me : Base corrompue

```bash
python manage_db.py reset
rm -rf ~/hp-z800-ai-agent/rag/vectordb/*
python index_documents.py
```

### Probl√®me : Indexation lente

- R√©duisez la taille des chunks
- Indexez par lots
- V√©rifiez que la GPU est utilis√©e

---

**üéâ Votre RAG est maintenant professionnel et performant !**
