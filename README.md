# hp-z800-ai-agent

ğŸ¤– Stack LLM complÃ¨te sur HP Z800 : Ollama + Open WebUI + RAG + Fine-tuning

## ğŸ¯ Objectif du Projet

Transformer le HP Z800 en serveur d'IA local avec :
- **Chatbot accessible depuis n'importe quel PC** via interface web
- **RAG (Retrieval Augmented Generation)** pour interroger vos documents
- **Fine-tuning** de modÃ¨les personnalisÃ©s
- **GPU acceleration** avec NVIDIA Quadro P4000

## ğŸ“Š SpÃ©cifications du Serveur

| Composant | DÃ©tails |
|-----------|---------|
| **ModÃ¨le** | HP Z800 Workstation (2009-2010) |
| **CPU** | 2Ã— Intel Xeon E5640 @ 2.67 GHz (8 cÅ“urs, 16 threads) |
| **RAM** | 12 GB DDR3 ECC |
| **GPU** | NVIDIA Quadro P4000 (8 GB GDDR5, 1792 CUDA cores) |
| **OS** | Ubuntu Server 22.04 LTS (noyau 6.8.0-40-generic HWE) |
| **Storage** | Disque 1: SystÃ¨me / Disque 2: Conda & ML |

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           HP Z800 (Serveur Local)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  ğŸ”· Ollama (Port 11434)                         â”‚
â”‚     â”œâ”€ mistral (LLM principal)                  â”‚
â”‚     â””â”€ nomic-embed-text (embeddings RAG)        â”‚
â”‚                                                  â”‚
â”‚  ğŸ”· Open WebUI (Port 3000) [Docker]             â”‚
â”‚     â”œâ”€ Interface chat web                       â”‚
â”‚     â”œâ”€ Upload & gestion documents               â”‚
â”‚     â”œâ”€ RAG automatique                          â”‚
â”‚     â””â”€ Collections de connaissances             â”‚
â”‚                                                  â”‚
â”‚  ğŸ”· Conda Environments (Disque 2)               â”‚
â”‚     â””â”€ fine-tuning (PyTorch, Transformers)      â”‚
â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†‘
         â”‚ http://IP-Z800:3000
         â”‚
    [Votre PC - Navigateur Web]
```

## ğŸš€ Installation Rapide

### PrÃ©requis
- âœ… Ubuntu Server 22.04 LTS installÃ©
- âœ… Pilotes NVIDIA installÃ©s
- âœ… Conda installÃ©
- âœ… AccÃ¨s sudo

### Installation Automatique

```bash
# Cloner le projet
git clone https://github.com/VOTRE-USERNAME/hp-z800-ai-agent.git
cd hp-z800-ai-agent

# Lancer l'installation complÃ¨te
chmod +x scripts/install-all.sh
./scripts/install-all.sh
```

## ğŸ“š Installation Manuelle (Ã‰tape par Ã‰tape)

Si vous prÃ©fÃ©rez installer manuellement, suivez ces guides dans l'ordre :

1. **[PrÃ©paration](docs/01-preparation.md)** - VÃ©rifications systÃ¨me
2. **[Installation Docker](docs/02-installation-docker.md)** - Docker & Docker Compose
3. **[Installation Ollama](docs/03-installation-ollama.md)** - Backend LLM
4. **[Installation Open WebUI](docs/04-installation-open-webui.md)** - Interface web
5. **[Configuration RAG](docs/05-configuration-rag.md)** - ModÃ¨les d'embedding
6. **[AccÃ¨s Distant](docs/06-acces-distant.md)** - Configurer l'accÃ¨s depuis votre PC
7. **[Fine-tuning Setup](docs/07-finetuning-setup.md)** - Environnement pour fine-tuning

## ğŸ’¡ Utilisation

### AccÃ¨s Ã  l'Interface Web

```
http://IP-DU-Z800:3000
```

**PremiÃ¨re connexion** :
1. CrÃ©er un compte (local, pas de cloud)
2. SÃ©lectionner le modÃ¨le "mistral"
3. Commencer Ã  discuter !

### Upload de Documents (RAG)

1. Cliquez sur **"+"** â†’ **"Upload Files"**
2. SÃ©lectionnez vos fichiers (PDF, DOCX, TXT, MD, CSV)
3. Le systÃ¨me indexe automatiquement
4. Posez des questions sur vos documents !

### API REST (pour scripts/intÃ©grations)

```bash
# GÃ©nÃ©ration de texte
curl http://IP-DU-Z800:11434/api/generate -d '{
  "model": "mistral",
  "prompt": "Explique-moi le RAG",
  "stream": false
}'
```

```python
# Client Python
import requests

def ask_mistral(prompt):
    response = requests.post(
        "http://IP-DU-Z800:11434/api/generate",
        json={"model": "mistral", "prompt": prompt, "stream": False}
    )
    return response.json()['response']

print(ask_mistral("Qu'est-ce que le machine learning?"))
```

## ğŸ“ FonctionnalitÃ©s AvancÃ©es

### RAG (Retrieval Augmented Generation)

Interrogez vos propres documents :
- Documentation technique
- Manuels d'utilisation
- Articles de recherche
- Notes personnelles
- Bases de connaissances

### Fine-tuning (Ã€ venir)

Environnement Conda configurÃ© pour :
- Fine-tuner Mistral sur vos donnÃ©es
- CrÃ©er des modÃ¨les spÃ©cialisÃ©s
- EntraÃ®ner des adapters LoRA

```bash
# Activer l'environnement
conda activate finetuning

# Voir docs/07-finetuning-setup.md pour plus de dÃ©tails
```

## ğŸ“ Structure du Projet

```
hp-z800-ai-agent/
â”œâ”€â”€ README.md                      # Ce fichier
â”œâ”€â”€ docs/                          # Documentation dÃ©taillÃ©e
â”‚   â”œâ”€â”€ 01-preparation.md
â”‚   â”œâ”€â”€ 02-installation-docker.md
â”‚   â”œâ”€â”€ 03-installation-ollama.md
â”‚   â”œâ”€â”€ 04-installation-open-webui.md
â”‚   â”œâ”€â”€ 05-configuration-rag.md
â”‚   â”œâ”€â”€ 06-acces-distant.md
â”‚   â”œâ”€â”€ 07-finetuning-setup.md
â”‚   â””â”€â”€ troubleshooting.md
â”œâ”€â”€ scripts/                       # Scripts d'installation
â”‚   â”œâ”€â”€ install-all.sh            # Installation complÃ¨te
â”‚   â”œâ”€â”€ install-docker.sh
â”‚   â”œâ”€â”€ install-ollama.sh
â”‚   â”œâ”€â”€ install-open-webui.sh
â”‚   â”œâ”€â”€ setup-finetuning-env.sh
â”‚   â”œâ”€â”€ test-gpu.sh
â”‚   â””â”€â”€ monitor.sh
â”œâ”€â”€ config/                        # Configurations
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ ollama.service
â”‚   â””â”€â”€ open-webui.env
â”œâ”€â”€ examples/                      # Exemples de code
â”‚   â”œâ”€â”€ api-chat.py
â”‚   â”œâ”€â”€ rag-query.py
â”‚   â””â”€â”€ batch-processing.py
â””â”€â”€ logs/                          # Logs d'installation
    â””â”€â”€ .gitkeep
```

## ğŸ”§ Scripts Utiles

```bash
# Monitoring GPU en temps rÃ©el
./scripts/monitor.sh

# Test complet de la configuration
./scripts/test-gpu.sh

# RedÃ©marrer tous les services
docker restart open-webui
sudo systemctl restart ollama
```

## ğŸ› ï¸ ModÃ¨les Disponibles

| ModÃ¨le | Taille | Usage | RAM Requise |
|--------|--------|-------|-------------|
| **mistral** | 4.1 GB | Chat principal | 8 GB |
| **nomic-embed-text** | 274 MB | Embeddings RAG | 2 GB |
| llama3.2 | 2 GB | Alternative lÃ©gÃ¨re | 4 GB |
| codellama | 3.8 GB | Code generation | 8 GB |

```bash
# TÃ©lÃ©charger un nouveau modÃ¨le
ollama pull nom-du-modele

# Lister les modÃ¨les installÃ©s
ollama list
```

## ğŸ”’ SÃ©curitÃ©

### Configuration Firewall

```bash
# Autoriser uniquement votre IP
sudo ufw allow from VOTRE-IP to any port 3000
sudo ufw allow from VOTRE-IP to any port 11434
sudo ufw enable
```

### Tunnel SSH (Alternative sÃ©curisÃ©e)

```bash
# Depuis votre PC
ssh -L 3000:localhost:3000 -L 11434:localhost:11434 user@IP-Z800

# Puis accÃ©dez Ã  http://localhost:3000
```

## ğŸ“Š Monitoring

```bash
# VÃ©rifier l'utilisation GPU
watch -n 1 nvidia-smi

# Logs Open WebUI
docker logs -f open-webui

# Logs Ollama
sudo journalctl -u ollama -f

# Statut des services
docker ps
sudo systemctl status ollama
```

## ğŸ†˜ DÃ©pannage

### ProblÃ¨me : Open WebUI ne dÃ©marre pas

```bash
docker logs open-webui
docker restart open-webui
```

### ProblÃ¨me : ModÃ¨le ne charge pas

```bash
# VÃ©rifier l'espace disque
df -h

# VÃ©rifier la mÃ©moire
free -h

# RÃ©installer le modÃ¨le
ollama rm mistral
ollama pull mistral
```

### ProblÃ¨me : GPU non utilisÃ©e

```bash
# VÃ©rifier NVIDIA
nvidia-smi

# VÃ©rifier les variables d'environnement Ollama
sudo systemctl show ollama | grep CUDA
```

Voir [docs/troubleshooting.md](docs/troubleshooting.md) pour plus de solutions.

## ğŸ“– Ressources

- [Documentation Ollama](https://github.com/ollama/ollama)
- [Documentation Open WebUI](https://docs.openwebui.com)
- [Guide RAG avec Ollama](https://ollama.com/blog/embedding-models)
- [Fine-tuning LLMs](https://huggingface.co/docs/transformers/training)

## ğŸ¤ Contribution

Ce projet documente l'installation complÃ¨te d'une stack LLM sur ancien hardware workstation. N'hÃ©sitez pas Ã  :
- Signaler des bugs
- Proposer des amÃ©liorations
- Partager vos configurations

## ğŸ“ License

MIT

## âœ… Roadmap

- [x] Installation Ollama
- [x] Installation Open WebUI
- [x] Configuration RAG
- [x] AccÃ¨s distant sÃ©curisÃ©
- [ ] Fine-tuning environment
- [ ] Datasets de fine-tuning
- [ ] ModÃ¨les custom
- [ ] API avancÃ©e
- [ ] Monitoring dashboards

---

**Fait avec â¤ï¸ sur un HP Z800 de 2009 qui tourne encore comme une horloge**
```bash
# VÃ©rification des pilotes NVIDIA
nvidia-smi

# VÃ©rification des dis
